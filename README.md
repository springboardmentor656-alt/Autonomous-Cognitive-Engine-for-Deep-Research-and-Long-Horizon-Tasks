# Autonomous-Cognitive-Engine-for-Deep-Research-and-Long-Horizon-Tasks
PROJECT OVERVIEW

This project implements an Autonomous Multi-Agent Research System capable of handling complex, long-horizon research tasks with minimal human intervention.

Instead of simple question-answering, this system:

Understands a complex research prompt

Breaks it into structured sub-tasks

Executes each task step-by-step

Stores intermediate outputs in memory

Synthesizes a final professional report

Evaluates its own performance

The architecture simulates how a human researcher works end-to-end.

Project Objectives

Build a multi-step autonomous cognitive agent

Implement planning + orchestration + execution workflow

Enable file-based working memory (Virtual File System)

Support long-form report generation

Integrate LLM-as-a-Judge evaluation

Log experiments using LangSmith

ğŸ—ï¸ System Architecture

The system is built using a LangGraph-style cognitive workflow with modular components.

ğŸ§© Core Components
1ï¸âƒ£ Planning Node (Strategic Thinking)

Receives user input

Breaks the research prompt into 4â€“6 structured tasks

Stores tasks inside state["todos"]

state["todos"] = todos

ğŸ‘‰ Converts vague prompts into actionable research steps.

2ï¸âƒ£ Orchestrator Node (Control Flow Brain)

Checks if tasks are remaining

Sends next task to worker

Moves to synthesis when all tasks are complete

if state["todos"]:
    return {"next": "execute"}
else:
    return {"next": "synthesize"}

ğŸ‘‰ Controls the entire execution loop.

3ï¸âƒ£ Worker Node (Execution Engine)

Picks one task at a time

Executes it using LLM

Stores output in memory

next_task = state["todos"].pop(0)
state["files"][filename] = result

ğŸ‘‰ Simulates research step execution.

4ï¸âƒ£ Virtual File System (Memory Layer)

Stores:

Research notes

Intermediate summaries

Final report

state["files"][filename] = content

ğŸ‘‰ Enables long-horizon reasoning across steps.

5ï¸âƒ£ Synthesis Node (Final Report Generator)

Combines all stored research outputs

Generates a structured 1200+ word professional report

Saves as final_report.txt

state["files"]["final_report.txt"] = final_report

ğŸ‘‰ Produces the final deliverable.

6ï¸âƒ£ LLM-as-a-Judge (Evaluation System)

Instead of external APIs like Gemini, this project uses:

ğŸ¦™ Local LLaMA model via Ollama

judge_llm = ChatOllama(model="llama3", temperature=0)

The evaluator:

Grades the report from 1â€“10

Returns a numeric score

Logs results in LangSmith

Advantages:

âœ… No API cost

âœ… Offline execution

âœ… Reproducible scoring

âœ… No dependency on external API keys

ğŸ”„ Complete Workflow (Input â†’ Output)

User prompt is received

Planning node generates structured research steps

Orchestrator controls task execution loop

Worker executes each task

Outputs are stored in Virtual File System

Synthesis node generates final report

Final report returned to LangSmith

LLaMA evaluator assigns score (1â€“10)

This creates a fully autonomous research pipeline.

ğŸ“‚ Project Structure
.
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ planning_node.py
â”‚   â”œâ”€â”€ orchestrator_node.py
â”‚   â”œâ”€â”€ worker_node.py
â”‚   â”œâ”€â”€ synthesis_node.py
â”‚   â”œâ”€â”€ state.py
â”‚   â””â”€â”€ graph.py
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ vfs.py
â”‚   â”œâ”€â”€ write_todos.py
â”‚   â””â”€â”€ delegation_tool.py
â”‚
â”œâ”€â”€ evaluator.py
â”œâ”€â”€ run_milestone4_experiment.py
â”œâ”€â”€ main.py
â””â”€â”€ README.md
ğŸ“Š Milestone Progression
âœ… Milestone 1 â€“ Strategic Planning

Built planner agent

Generated structured TODO list

Basic multi-step reasoning

âœ… Milestone 2 â€“ Memory & Tool Integration

Implemented Virtual File System

Enabled file storage & reading

Added task tracking

Integrated LangSmith tracing

âœ… Milestone 3 â€“ Long-Horizon Execution

Added orchestrator node

Implemented task delegation

Structured research pipeline

Improved prompt engineering

âœ… Milestone 4 â€“ Evaluation & Full Integration

Unified all components in a single StateGraph

Generated complete long-form research reports

Integrated LLaMA-based automated evaluation

Logged full experiments in LangSmith

Measured research quality with 1â€“10 scoring scale

ğŸ“Š Evaluation Results

Average score across tasks: ~7â€“8 / 10

High task completion rate

Structured and coherent outputs

Stable multi-step execution

The system demonstrates reliable autonomous research capability.

ğŸ› ï¸ Technologies Used

Python

LangChain

LangGraph-style workflow

Ollama (Local LLaMA)

LangSmith (Tracing & Experiments)

Virtual File System memory design

ğŸ’¡ Key Features

âœ” Multi-agent cognitive architecture
âœ” Autonomous task planning
âœ” Loop-based execution control
âœ” Long-form research synthesis
âœ” Local LLaMA evaluation
âœ” LangSmith experiment tracking
âœ” Cost-free offline grading

ğŸ“ Learning Outcomes

This project demonstrates:

Multi-agent system design

Long-horizon reasoning architecture

Prompt engineering for complex tasks

LLM-based evaluation methods

Tool-driven agent workflows

Experiment tracking & debugging with LangSmith

ğŸš€ Final Outcome

Milestone 4 successfully delivers:

A fully autonomous research engine capable of planning, executing, synthesizing, and evaluating complex research tasks end-to-end.
